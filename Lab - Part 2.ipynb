{
 "metadata": {
  "name": "Lab - Part 2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nencoding=utf8\n\n1.Download data from: http://www.cs.bgu.ac.il/~nlpproj/fs/classificationExample.zip\n2. Unzip\n3.Assign workDir the path where you unzipped the data\n\"\"\"\nimport os\nprint os.getcwd()\n\nos.chdir(\"medicalhebrew-master\")\n\nfilesDir = \"sample\"\n\n\"\"\"\nSanity Check\n\"\"\"\nprint os.listdir(filesDir)[0]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "WindowsError",
       "evalue": "[Error 2] The system cannot find the file specified: 'medicalhebrew-master'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-1eb0ccbda051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"medicalhebrew-master\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mfilesDir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sample\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mWindowsError\u001b[0m: [Error 2] The system cannot find the file specified: 'medicalhebrew-master'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "C:\\Users\\cohenr5\\Documents\\IPython Notebooks\\medicalhebrew-master\n"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nEncoding is magic\nin this case we need to decode\n\"\"\"\nprint os.listdir(filesDir)[0]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "0-lung\n"
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nRead the texts\n\"\"\"\nfrom codecs import open\ndocs = {}\nfor f in os.listdir(filesDir):\n    fin = open(os.path.join(filesDir,f),\"r\",\"utf8\")\n    docs[f] = fin.read()\n    \n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nSanity check!\n\"\"\"\nprint docs.values()[0]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\u05de\u05de\u05e6\u05d0\u05d9\u05dd \u05db\u05d0\u05dc\u05d5 \u05d9\u05db\u05d5\u05dc\u05d9\u05dd \u05dc\u05d4\u05ea\u05d0\u05d9\u05dd \u05d2\u05dd \u05dc\u05d2\u05e8\u05d5\u05e8\u05d5\u05ea  \n\u05d0\u05d1\u05dc \u05d9\u05e9 \u05e6\u05d5\u05e8\u05da \u05d1\u05d4\u05e2\u05e8\u05db\u05d4 \u05e9\u05dc \u05e8\u05d5\u05e4\u05d0 \u05d1\u05d4\u05e7\u05d3\u05dd \u05db\u05d3\u05d9 \u05dc\u05d4\u05de\u05e9\u05d9\u05da \u05d1\u05d9\u05e8\u05d5\u05e8 \n\u05dc\u05d3\u05d5\u05d2\u05de\u05d0 \u05e2\u05dd \u05e1\u05d9 \u05d8\u05d9 \u05db\u05dc \u05d2\u05d5\u05e4\u05d9 \u05d1\u05d3\u05d9\u05e7\u05d5\u05ea \u05d3\u05dd \n\u05d5\u05db\u05e0\u05e8\u05d0\u05d4 \u05d2\u05dd \u05d1\u05d9\u05d5\u05e4\u05e1\u05d9\u05d4 \u05d0\u05dd \u05d9\u05d4\u05d9\u05d4 \u05e6\u05d5\u05e8\u05da \u05d1\u05db\u05da \n\u05e9\u05d5\u05d1 \u05e6\u05d9\u05dc\u05d5\u05dd \u05d7\u05d6\u05d4 \u05d1\u05d5\u05d3\u05d3 \u05d0\u05d9\u05e0\u05d5 \u05de\u05e1\u05e4\u05d9\u05e7 \u05dc\u05d4\u05e2\u05e8\u05db\u05d4 \u05de\u05d4\u05d9 \u05d4\u05d0\u05d1\u05d7\u05e0\u05d4 \u05d5\u05d7\u05d9\u05d9\u05d1\u05d9\u05dd \u05d4\u05de\u05e9\u05da \u05d1\u05d9\u05e8\u05d5\u05e8\n\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nDr. House question - can you tell the class? \nHint - it's not lopus\n\"\"\"\nprint docs.keys()[0].decode(\"cp1255\")\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "170-lung\n"
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nwrite a tokenization funciton\n\"\"\"\n#some tokenization and cleansing\ndef tokenize(mytext):\n    cleantext = mytext.replace(\",\", \" , \").replace(\"-\", \" \").replace(\"?\", \" \").replace(\")\", \" ) \").replace(\"(\", \" ( \").replace(\"'\", \" \").replace(\"\\%\", \" % \").replace(\"\\r\\n\",\" . \").replace(\"\\!\", \" ! \").replace(\"\\t\", \" \")\n    cleantext = cleantext.replace(\"/\", \" \").replace(\".\", \" \")\n    cleantext = cleantext.replace(\"\\r\", \"\").replace(\"\\n\",\" \")\n    return cleantext\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "fout = open(\"mydata1.txt\",\"w\",\"utf8\")\nfout.write(\"class\\ttexts\\n\")\n\nfor doc in docs:\n    mylabel = \"blood\"\n    if unicode(\"lung\",encoding=\"utf8\") in unicode(doc,encoding=\"utf8\"):\n        mylabel = \"lung\"\n    fout.write(mylabel+\"\\t\"+tokenize(docs[doc])+\"\\n\")\nfout.close()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nRead the data into a panda data frame\n\"\"\"\nimport pandas as pd\nimport numpy\ndf = pd.read_csv(\"mydata1.txt\",sep=\"\\t\",header=0,encoding=\"utf8\")\nnumpy.random.seed(5)\ndf2 = df.reindex(numpy.random.permutation(df.index))",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.feature_extraction.text import TfidfVectorizer\n#Minimal frequency should be much higher for big data (50-100)\nMINIMAL_FREQUENCY = 4 \n# token appearing in more than 10-30% may be an in domain stop word (\"EMC\")\nMAXIMAL_FREQUENCY_FRACTION = 0.3 \n#We have 40 samples, so 40 features should be safe\nNUMBER_OF_FEATURES = 100\nvectorizer = TfidfVectorizer(sublinear_tf=True, max_df=MAXIMAL_FREQUENCY_FRACTION, min_df = MINIMAL_FREQUENCY,ngram_range = (1,1),max_features=NUMBER_OF_FEATURES)\nX = vectorizer.fit_transform(numpy.asarray(df2.texts)).toarray()\n\nfor w in vectorizer.__dict__[\"vocabulary_\"]:\n    print w",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\u05d9\u05e2\u05d5\u05e5\n\u05d1\u05e8\u05d6\u05dc\n\u05d0\u05d1\u05dc\n\u05d4\u05e9\u05d0\u05dc\u05d4\n\u05dc\u05d1\u05e6\u05e2\n\u05d3\u05dd\n\u05de\u05d8\u05e4\u05dc\n\u05d9\u05ea\u05db\u05df\n\u05d4\u05d0\u05dd\n\u05e2\u05d5\u05d6\u05d9\n\u05dc\u05e4\u05d9\n\u05de\u05d4\n\u05dc\u05d8\u05d9\u05e4\u05d5\u05dc\n\u05d4\u05de\u05d8\u05d5\u05dc\u05d5\u05d2\n\u05db\u05de\u05d5\n\u05d0\u05d9\u05df\n\u05d3\u05e8\n\u05db\u05dc\u05dc\n\u05d7\u05d5\u05d1\u05d1\n\u05d1\u05e7\u05e8\u05d9\u05e9\u05d4\n\u05d0\u05e0\u05d9\n\u05e6\u05e8\u05d9\u05da\n\u05e9\u05dc\u05d5\u05dd\n\u05de\u05d3\u05d5\u05d1\u05e8\n\u05d1\u05d3\u05d9\u05e7\u05d5\u05ea\n\u05e8\u05e6\u05d5\u05d9\n\u05e7\u05e9\u05e8\n\u05d1\u05d1\u05e8\u05db\u05d4\n\u05d7\u05d6\u05d4\n\u05dc\u05da\n\u05dc\u05d9\n\u05e9\u05d9\u05e9\n\u05d8\u05d9\u05e4\u05d5\u05dc\n\u05de\u05e7\u05e8\u05d4\n\u05e1\u05e8\u05d8\u05df\n\u05d5\u05dc\u05d0\n\u05dc\u05ea\u05ea\n\u05d7\u05e9\u05d5\u05d1\n\u05de\u05d0\u05d3\n\u05dc\u05d3\u05e2\u05ea\n\u05d0\u05e6\u05dc\n\u05d4\u05de\u05d7\u05dc\u05d4\n\u05d1\u05e8\u05d1\u05d9\n\u05dc\u05e7\u05d1\u05dc\n\u05db\u05d3\u05d9\n\u05d1\u05db\u05dc\n\u05d0\u05d5\n\u05d1\u05d4\u05d7\u05dc\u05d8\n\u05d9\u05ea\u05e8\n\u05e7\u05e8\u05d9\u05e9\u05d4\n\u05d1\u05d3\u05d9\u05e7\u05ea\n\u05d1\u05d3\u05d9\u05e7\u05d4\n\u05d1\u05e8\u05d5\u05e8\n\u05d4\u05d8\u05d9\u05e4\u05d5\u05dc\n\u05e4\u05e8\u05d5\u05e4\n\u05d1\u05d9\u05df\n\u05dc\u05d7\u05d6\u05d5\u05e8\n\u05d2\u05d1\u05d5\u05d4\n\u05d5\u05dc\u05db\u05df\n\u05d6\u05d4\n\u05e2\u05dd\n\u05d4\u05d9\u05d0\n\u05de\u05e6\u05d9\u05e2\n\u05d1\u05d4\u05e6\u05dc\u05d7\u05d4\n\u05d0\u05da\n\u05d0\u05dd\n\u05d4\u05e8\u05d5\u05e4\u05d0\n\u05e0\u05e8\u05d0\u05d4\n\u05db\u05da\n\u05db\u05d9\n\u05db\u05dc\n\u05d2\u05dd\n\u05d9\u05db\u05d5\u05dc\n\u05e8\u05e7\n\u05de\u05e1\u05e4\u05e8\n\u05dc\u05d1\u05d3\u05d5\u05e7\n\u05dc\u05d4\u05d9\u05d5\u05ea\n\u05e6\u05d5\u05e8\u05da\n\u05e0\u05d9\u05ea\u05df\n\u05d9\u05d5\u05ea\u05e8\n\u05d9\u05d6\u05d4\u05e8\n\u05dc\u05e8\u05d0\u05d5\u05ea\n\u05db\u05d3\u05d0\u05d9\n\u05e8\u05d5\u05e4\u05d0\n\u05dc\u05d0\u05d7\u05e8\n\u05d4\u05e2\u05d5\u05e1\u05e7\n\u05dc\u05d2\u05d1\u05d9\n\u05dc\u05e8\u05d5\u05e4\u05d0\n\u05db\u05df\n\u05d4\u05d1\u05d3\u05d9\u05e7\u05d5\u05ea\n\u05de\u05de\u05dc\u05d9\u05e5\n\u05dc\u05e4\u05e0\u05d9\n\u05e7\u05e9\u05d4\n\u05e9\u05dc\u05da\n\u05d1\u05de\u05d9\u05d3\u05d4\n\u05d6\u05d5\n\u05dc\u05e4\u05e0\u05d5\u05ea\n\u05e9\u05d0\u05ea\n\u05d4\u05d5\u05d0\n\u05d6\u05d0\u05ea\n"
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "TEST_SIZE = 500\nY= numpy.asarray(df2[\"class\"])\ntrain_x = X[:-TEST_SIZE]\ntrain_y = list(Y[:-TEST_SIZE])\ntest_x  = X[-TEST_SIZE:]\ntest_y  = list(Y[-TEST_SIZE:])\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from sklearn.metrics import f1_score,classification_report\nfrom sklearn.naive_bayes import MultinomialNB\ndef trainTestModel(train_x,train_y,test_x,test_y,model):\n    print \"training\"\n    model.fit(train_x, train_y)\n    print \"test\"\n    pred = model.predict(test_x)\n    try:\n        print classification_report(test_y, pred)\n    except:\n        print \"Error\"\n    return True\nclf = MultinomialNB()\ntrainTestModel(train_x,train_y,test_x,test_y,clf)\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "training\ntest\n             precision    recall  f1-score   support\n\n      blood       0.89      0.94      0.91       319\n       lung       0.88      0.80      0.83       181\n\navg / total       0.89      0.89      0.88       500\n\n"
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 119,
       "text": "True"
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "\"\"\"\nEvaluate the model qualitatively\nAre the features really robust?\n\"\"\"\nfnames = list(numpy.asarray(vectorizer.get_feature_names()))\nfeatures = []\nfor sclass,weights in zip(clf.classes_,clf.coef_):\n    features += [(abs(weight),feat) for weight,feat in zip(weights,fnames)]\nfeatures.sort(reverse=True)\nfor weight,word in features[:50]:\n    print word",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\u05e7\u05e8\u05d9\u05e9\u05d4\n\u05d4\u05e2\u05d5\u05e1\u05e7\n\u05d4\u05de\u05d8\u05d5\u05dc\u05d5\u05d2\n\u05d1\u05e8\u05d1\u05d9\n\u05d1\u05e7\u05e8\u05d9\u05e9\u05d4\n\u05d9\u05e2\u05d5\u05e5\n\u05d1\u05e8\u05d6\u05dc\n\u05d9\u05ea\u05e8\n\u05e4\u05e8\u05d5\u05e4\n\u05d4\u05d1\u05d3\u05d9\u05e7\u05d5\u05ea\n\u05dc\u05d7\u05d6\u05d5\u05e8\n\u05d3\u05dd\n\u05e8\u05e6\u05d5\u05d9\n\u05db\u05dc\u05dc\n\u05e6\u05d5\u05e8\u05da\n\u05dc\u05d3\u05e2\u05ea\n\u05d1\u05d4\u05d7\u05dc\u05d8\n\u05d2\u05d1\u05d5\u05d4\n\u05db\u05d3\u05d9\n\u05e7\u05e9\u05e8\n\u05e9\u05d0\u05ea\n\u05d1\u05e8\u05d5\u05e8\n\u05d1\u05d3\u05d9\u05e7\u05ea\n\u05d1\u05de\u05d9\u05d3\u05d4\n\u05d0\u05da\n\u05dc\u05e4\u05d9\n\u05de\u05e6\u05d9\u05e2\n\u05dc\u05e7\u05d1\u05dc\n\u05dc\u05d1\u05d3\u05d5\u05e7\n\u05e8\u05e7\n\u05de\u05e7\u05e8\u05d4\n\u05dc\u05e4\u05e0\u05d9\n\u05d4\u05e9\u05d0\u05dc\u05d4\n\u05dc\u05ea\u05ea\n\u05e0\u05e8\u05d0\u05d4\n\u05de\u05de\u05dc\u05d9\u05e5\n\u05dc\u05d1\u05e6\u05e2\n\u05db\u05df\n\u05dc\u05e4\u05e0\u05d5\u05ea\n\u05d1\u05d3\u05d9\u05e7\u05d4\n\u05dc\u05d8\u05d9\u05e4\u05d5\u05dc\n\u05d4\u05de\u05d7\u05dc\u05d4\n\u05e9\u05dc\u05da\n\u05d1\u05d9\u05df\n\u05db\u05da\n\u05d5\u05dc\u05d0\n\u05d9\u05ea\u05db\u05df\n\u05d9\u05db\u05d5\u05dc\n\u05d5\u05dc\u05db\u05df\n\u05d1\u05d3\u05d9\u05e7\u05d5\u05ea\n"
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}